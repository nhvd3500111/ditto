{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Download github repo","metadata":{"id":"_34HObszwKdY"}},{"cell_type":"code","source":"#just clone the repo\n!git clone https://github.com/nhvd3500111/ditto","metadata":{"execution":{"iopub.status.busy":"2022-06-11T19:48:33.724284Z","iopub.execute_input":"2022-06-11T19:48:33.725048Z","iopub.status.idle":"2022-06-11T19:48:39.596192Z","shell.execute_reply.started":"2022-06-11T19:48:33.725009Z","shell.execute_reply":"2022-06-11T19:48:39.594844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#In case you want to reupload ditto if you have made changes in the respective\n#github repo\n'''\nimport shutil\nshutil.rmtree(\"/kaggle/working/ditto\")\n%cd /kaggle/working/\n!git clone https://github.com/nhvd3500111/ditto\n%cd /kaggle/working/ditto\n'''\n","metadata":{"id":"PSgSb9vUtCyX","outputId":"13974356-4d68-40cd-aaac-11ee294871fa","execution":{"iopub.status.busy":"2022-06-11T18:28:46.000243Z","iopub.execute_input":"2022-06-11T18:28:46.000653Z","iopub.status.idle":"2022-06-11T18:28:50.73329Z","shell.execute_reply.started":"2022-06-11T18:28:46.000621Z","shell.execute_reply":"2022-06-11T18:28:50.732347Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install packages and fp16 optimization","metadata":{"id":"iX3OOr8bwRyk"}},{"cell_type":"code","source":"# First install requirements\n%cd /kaggle/working/ditto\n!pip install -r requirements.txt\n\n#Then some necessary imports\nimport nltk\nimport os\nimport time\nfrom IPython.display import FileLink\n\n\nnltk.download('stopwords')\n!git clone https://github.com/NVIDIA/apex\n%cd apex\n!pip install -v --no-cache-dir ./\n%cd ..\n# some issue with colab\n!pip install --upgrade \"urllib3==1.25.4\" awscli\n%cd /kaggle/working/ditto\n!pip install transformers\n!pip install tensorboardX\n!pip install jsonlines\n!pip install openpyxl\n","metadata":{"id":"L_hfO6D_uLby","outputId":"3b919d80-7be1-497c-f5eb-90cce9727e6f","execution":{"iopub.status.busy":"2022-06-11T19:48:39.599438Z","iopub.execute_input":"2022-06-11T19:48:39.603527Z","iopub.status.idle":"2022-06-11T19:50:15.741118Z","shell.execute_reply.started":"2022-06-11T19:48:39.603469Z","shell.execute_reply":"2022-06-11T19:50:15.740038Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the 2 pre-trained models that our Ditto models exploit","metadata":{}},{"cell_type":"code","source":"#This cell is executed at this point because of time - counting reasons, since we want the time\n#counted in every training session to be exclusively pure model - training time\n\n#Firstly we import AutoModel Class directly into our notebook \nfrom transformers import AutoModel\n\nAutoModel.from_pretrained('distilbert-base-uncased')\nAutoModel.from_pretrained('roberta-base')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-11T19:50:15.742923Z","iopub.execute_input":"2022-06-11T19:50:15.743548Z","iopub.status.idle":"2022-06-11T19:51:01.445634Z","shell.execute_reply.started":"2022-06-11T19:50:15.743486Z","shell.execute_reply":"2022-06-11T19:51:01.44476Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess - define the specific details of each run","metadata":{}},{"cell_type":"code","source":"datasets = [\"cameras\",  \"shoes\", \"watches\",\"computers\"]\nsizes = [\"small\", \"medium\",\"large\"]\nneurals = [\"gru\",\"linear\",\"cls_sep\",\"lstm\",\"cls_sep_gru\"]\ngpu_id = 0\n\n#we will execute two runs for each customized ditto_model , so we will define each\n#run's cuda.manual_seed for repetition reasons\nrun_ids=range(1,3)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-11T19:51:01.448264Z","iopub.execute_input":"2022-06-11T19:51:01.449205Z","iopub.status.idle":"2022-06-11T19:51:01.457663Z","shell.execute_reply.started":"2022-06-11T19:51:01.449163Z","shell.execute_reply":"2022-06-11T19:51:01.456605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train DITTO - Run Matcher\n","metadata":{}},{"cell_type":"code","source":"#wdc cameras small\n\nd=datasets[0]\nsize=sizes[0]\n\nfor dk in [False,True]:\n    for run_id in run_ids:\n        for neural in neurals:\n            if dk:\n                domain='product'\n            else:\n                domain = None\n            dataset = '_'.join(['wdc', d, size])\n            \n            print(\"-----------------------------------------------------------------------------------------\")\n            print (\"\\n\\nTask: \"+dataset+\"\\nNeural: \"+neural+\"\\nrun_id: \"+str(run_id)+\"\\nDomain Knowledge: \"+str(domain)+\"\\n\\n\")\n            \n            time_start=time.time()\n            \n            !CUDA_VISIBLE_DEVICES=$gpu_id python train_ditto.py \\\n              --task $dataset \\\n              --batch_size 32 \\\n              --max_len 128 \\\n              --n_epochs 20 \\\n              --finetuning \\\n              --save_model \\\n              --run_id $run_id \\\n              --da entry_swap \\\n              --dk $domain \\\n              --neural $neural  \n            \n            training_time=round(time.time()- time_start,2)\n\n            #Running the matcher to obtain the results. Remember to provide the same args as above\n\n            !CUDA_VISIBLE_DEVICES=$gpu_id python matcher.py \\\n              --task $dataset \\\n              --input_path data/wdc/$d/test.txt \\\n              --output_path output/output_small_1.jsonl \\\n              --max_len 128 \\\n              --use_gpu \\\n              --da entry_swap \\\n              --dk $domain \\\n              --checkpoint_path checkpoints/ \\\n              --neural $neural \\\n              --file_excel F1_SCORES.xlsx \\\n              --run_id $run_id \\\n              --time_trained $training_time\n            \n#After every completed for loop, we will download F1_SCORES.xlsx for security reasons\nFileLink(r'F1_SCORES.xlsx')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T15:13:11.49242Z","iopub.execute_input":"2022-06-11T15:13:11.493195Z","iopub.status.idle":"2022-06-11T17:53:20.626568Z","shell.execute_reply.started":"2022-06-11T15:13:11.493158Z","shell.execute_reply":"2022-06-11T17:53:20.625529Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#wdc shoes small\n\nd=datasets[1]\nsize=sizes[0]\n\nfor dk in [False,True]:\n    for run_id in run_ids:\n        for neural in neurals:\n            if dk:\n                domain='product'\n            else:\n                domain = None\n            dataset = '_'.join(['wdc', d, size])\n\n            print(\"-----------------------------------------------------------------------------------------\")\n            print (\"\\n\\nTask: \"+dataset+\"\\nNeural: \"+neural+\"\\nrun_id: \"+str(run_id)+\"\\nDomain Knowledge: \"+str(domain)+\"\\n\\n\")\n            \n            time_start=time.time()\n            \n            !CUDA_VISIBLE_DEVICES=$gpu_id python train_ditto.py \\\n              --task $dataset \\\n              --batch_size 32 \\\n              --max_len 128 \\\n              --n_epochs 20 \\\n              --finetuning \\\n              --save_model \\\n              --run_id $run_id \\\n              --da entry_swap \\\n              --dk $domain \\\n              --neural $neural  \n\n            training_time=round(time.time()- time_start,2)\n            \n            #Running the matcher to obtain the results. Remember to provide the same args as above\n            \n            !CUDA_VISIBLE_DEVICES=$gpu_id python matcher.py \\\n              --task $dataset \\\n              --input_path data/wdc/$d/test.txt \\\n              --output_path output/output_small_1.jsonl \\\n              --max_len 128 \\\n              --use_gpu \\\n              --da entry_swap \\\n              --dk $domain \\\n              --checkpoint_path checkpoints/ \\\n              --neural $neural \\\n              --file_excel F1_SCORES.xlsx \\\n              --run_id $run_id \\\n              --time_trained $training_time\n            \n            \n#After every completed for loop, we will download F1_SCORES.xlsx for security reasons\nFileLink(r'F1_SCORES.xlsx')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T19:51:01.460244Z","iopub.execute_input":"2022-06-11T19:51:01.461054Z","iopub.status.idle":"2022-06-11T22:37:09.279644Z","shell.execute_reply.started":"2022-06-11T19:51:01.461009Z","shell.execute_reply":"2022-06-11T22:37:09.278526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#wdc watches small\n\nd=datasets[2]\nsize=sizes[0]\n\nfor dk in [False,True]:\n    for run_id in run_ids:\n        for neural in neurals:\n            if dk:\n                domain='product'\n            else:\n                domain = None\n            dataset = '_'.join(['wdc', d, size])\n\n            print(\"-----------------------------------------------------------------------------------------\")\n            print (\"\\n\\nTask: \"+dataset+\"\\nNeural: \"+neural+\"\\nrun_id: \"+str(run_id)+\"\\nDomain Knowledge: \"+str(domain)+\"\\n\\n\")\n            \n            time_start=time.time()\n            \n            !CUDA_VISIBLE_DEVICES=$gpu_id python train_ditto.py \\\n              --task $dataset \\\n              --batch_size 32 \\\n              --max_len 128 \\\n              --n_epochs 20 \\\n              --finetuning \\\n              --save_model \\\n              --run_id $run_id \\\n              --da entry_swap \\\n              --dk $domain \\\n              --neural $neural  \n\n            training_time=round(time.time()- time_start,2)\n            \n            #Running the matcher to obtain the results. Remember to provide the same args as above\n            \n            !CUDA_VISIBLE_DEVICES=$gpu_id python matcher.py \\\n              --task $dataset \\\n              --input_path data/wdc/$d/test.txt \\\n              --output_path output/output_small_1.jsonl \\\n              --max_len 128 \\\n              --use_gpu \\\n              --da entry_swap \\\n              --dk $domain \\\n              --checkpoint_path checkpoints/ \\\n              --neural $neural \\\n              --file_excel F1_SCORES.xlsx \\\n              --run_id $run_id \\\n              --time_trained $training_time\n            \n            \n#After every completed for loop, we will download F1_SCORES.xlsx for security reasons\nFileLink(r'F1_SCORES.xlsx')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#wdc computers small\n\nd=datasets[3]\nsize=sizes[0]\n\nfor dk in [False,True]:\n    for run_id in run_ids:\n        for neural in neurals:\n            if dk:\n                domain='product'\n            else:\n                domain = None\n            dataset = '_'.join(['wdc', d, size])\n\n            print(\"-----------------------------------------------------------------------------------------\")\n            print (\"\\n\\nTask: \"+dataset+\"\\nNeural: \"+neural+\"\\nrun_id: \"+str(run_id)+\"\\nDomain Knowledge: \"+str(domain)+\"\\n\\n\")\n            \n            time_start=time.time()\n            \n            !CUDA_VISIBLE_DEVICES=$gpu_id python train_ditto.py \\\n              --task $dataset \\\n              --batch_size 32 \\\n              --max_len 128 \\\n              --n_epochs 20 \\\n              --finetuning \\\n              --save_model \\\n              --run_id $run_id \\\n              --da entry_swap \\\n              --dk $domain \\\n              --neural $neural  \n\n            training_time=round(time.time()- time_start,2)\n            \n            #Running the matcher to obtain the results. Remember to provide the same args as above\n            \n            !CUDA_VISIBLE_DEVICES=$gpu_id python matcher.py \\\n              --task $dataset \\\n              --input_path data/wdc/$d/test.txt \\\n              --output_path output/output_small_1.jsonl \\\n              --max_len 128 \\\n              --use_gpu \\\n              --da entry_swap \\\n              --dk $domain \\\n              --checkpoint_path checkpoints/ \\\n              --neural $neural \\\n              --file_excel F1_SCORES.xlsx \\\n              --run_id $run_id \\\n              --time_trained $training_time\n            \n            \n#After every completed for loop, we will download F1_SCORES.xlsx for security reasons\nFileLink(r'F1_SCORES.xlsx')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#wdc all medium\n\nd='all'\nsize=sizes[1]\n\n\nfor run_id in run_ids:\n    for neural in neurals:\n        dataset = '_'.join(['wdc', d, size])\n\n        print(\"-----------------------------------------------------------------------------------------\")\n        print (\"\\n\\nTask: \"+dataset+\"\\nNeural: \"+neural+\"\\nrun_id: \"+str(run_id)+\"\\nDomain Knowledge: \"+str(domain)+\"\\n\\n\")\n\n        time_start=time.time()\n\n        !CUDA_VISIBLE_DEVICES=$gpu_id python train_ditto.py \\\n          --task $dataset \\\n          --batch_size 32 \\\n          --max_len 128 \\\n          --n_epochs 20 \\\n          --finetuning \\\n          --save_model \\\n          --run_id $run_id \\\n          --da del \\\n          --neural $neural  \n\n        training_time=round(time.time()- time_start,2)\n\n        #Running the matcher to obtain the results. Remember to provide the same args as above\n\n        !CUDA_VISIBLE_DEVICES=$gpu_id python matcher.py \\\n          --task $dataset \\\n          --input_path data/wdc/$d/test.txt \\\n          --output_path output/output_small_1.jsonl \\\n          --max_len 128 \\\n          --use_gpu \\\n          --da del \\\n          --checkpoint_path checkpoints/ \\\n          --neural $neural \\\n          --file_excel F1_SCORES.xlsx \\\n          --run_id $run_id \\\n          --time_trained $training_time\n\n\n#After every completed for loop, we will download F1_SCORES.xlsx for security reasons\nFileLink(r'F1_SCORES.xlsx')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cheat script to download the whole ditto folder from kaggle/working and extracting \n#the excel file  from there, because there is a bug in kaggle's working directory\n\n'''\n%cd /kaggle/working\nimport shutil\nshutil.make_archive('lala', 'zip', '/kaggle/working/ditto')\n#%cd /kaggle/working\nFileLink(r'lala.zip')\n'''","metadata":{},"execution_count":null,"outputs":[]}]}